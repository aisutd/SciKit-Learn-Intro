{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to SciKit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Amol Mavuduru\n",
    "\n",
    "Notebook Created: October 2017\n",
    "\n",
    "This notebook is designed to give you a brief introduction to scikit-learn, a library that has become one of the most popular machine learning frameworks for python. This library is designed with Object-Oriented Programming (OOP) principles in mind and consequently it is intuitive and easy to use. In just a few lines of code, you can initialize, train, and test anything from simple algorithms like Linear Classifiers and Decision Trees to cutting-edge machine learning algorithms such as Support Vector Machines, Random Forests, and even deep Neural Networks. \n",
    "\n",
    "The documentation website for scikit-learn can be found here: http://scikit-learn.org/stable/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check out the following link: http://scikit-learn.org/stable/install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the following dependencies:\n",
    "    - Python (>= 2.7 or >= 3.3) (If you have 2.7 or 3.3 or higher either should be fine)\n",
    "    - Numpy\n",
    "    - Pandas (This is specific to our demo)\n",
    "    - Scipy \n",
    "\n",
    "If you don't have Scipy, but you have Python and Numpy you should be fine, since if pip does not find Scipy on your system it will probably install it for you when you install scikit-learn.\n",
    "\n",
    "To install sklearn, just go to your terminal and issue the following command:\n",
    "##### pip install sklearn\n",
    "\n",
    "Note that you can install all of the above dependencies using pip as well.\n",
    "\n",
    "Once scikit-learn is installed you should be ready to follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Demo: Working with an Actual Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo we are going to use scikit-learn to train and test machine learning models on a real dataset! This dataset is designed to aid in Breast Cancer diagnosis and has been made publicly available at both the UCI Machine Learning repository, and on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Name: Breast Cancer Wisconsin (Diagnostic)\n",
    "- Kaggle Link: https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "- UCI Machine Learning Link: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the problem we are trying to solve \n",
    "\n",
    "Our goal is to build a machine learning model that can take into account the features of a cell in this dataset and essentially diagnose a tumor as \"benign\" or \"malignant\". This is a \"binary classification\" problem, which means we want to develop a model that can classify a tumor as belonging to one of two classes, which are \"benign\" (B) and \"malignant\" (M). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np   # For linear algebra\n",
    "import pandas as pd  # For data preprocessing and CSV File I/O\n",
    "import sklearn  # For training machine learning models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The libraries below are optional, but I will use them for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in and exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data.csv file should be in the same directory as this notebook and this is the case in the Github repository. We can use pandas to read in the csv file as an object called a dataframe using the read_csv function.\n",
    "\n",
    "After that we can display the first 5 rows of the dataframe using the head() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contains several features and a diagnosis label (or class) that is either B or M to indicate a benign or malignant tumor respectively.\n",
    "Now that we know what our data looks like, we can get some general information about the data using the info() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      "id                         569 non-null int64\n",
      "diagnosis                  569 non-null object\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "Unnamed: 32                0 non-null float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at some general statistics about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean     ...       texture_worst  perimeter_worst  \\\n",
       "count     569.000000     ...          569.000000       569.000000   \n",
       "mean        0.181162     ...           25.677223       107.261213   \n",
       "std         0.027414     ...            6.146258        33.602542   \n",
       "min         0.106000     ...           12.020000        50.410000   \n",
       "25%         0.161900     ...           21.080000        84.110000   \n",
       "50%         0.179200     ...           25.410000        97.660000   \n",
       "75%         0.195700     ...           29.720000       125.400000   \n",
       "max         0.304000     ...           49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
       "count            569.000000      569.000000               569.000000   \n",
       "mean               0.114606        0.290076                 0.083946   \n",
       "std                0.065732        0.061867                 0.018061   \n",
       "min                0.000000        0.156500                 0.055040   \n",
       "25%                0.064930        0.250400                 0.071460   \n",
       "50%                0.099930        0.282200                 0.080040   \n",
       "75%                0.161400        0.317900                 0.092080   \n",
       "max                0.291000        0.663800                 0.207500   \n",
       "\n",
       "       Unnamed: 32  \n",
       "count          0.0  \n",
       "mean           NaN  \n",
       "std            NaN  \n",
       "min            NaN  \n",
       "25%            NaN  \n",
       "50%            NaN  \n",
       "75%            NaN  \n",
       "max            NaN  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do a little bit of preprocessing and split our data into a set of features (X) and a set of target labels (y). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 32', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.drop(['id', 'diagnosis'], axis=1)\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean           ...             radius_worst  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    M\n",
       "1    M\n",
       "2    M\n",
       "3    M\n",
       "4    M\n",
       "Name: diagnosis, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, we always need a way to evaluate our models. In order to do this, we want to split our data into a training set and a testing set. Rather than training our model on the entire dataset for the purpose evaluation, we only train the model on the training test first and then evaluate the model's performance in predicting the class of samples on the test set. \n",
    "\n",
    "This practice, which is sometimes referred to as cross-validation, is designed to simulate our model's performance on unseen data and provides a measure of the ability of our model to generalize to a broader variety of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # This function is necessary to split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What train_test_split does:\n",
    "\n",
    "- Takes in two dataframes, X and y as parameters corresponding to the features and target column. \n",
    "- Contains a parameter called test_size that allows you to specify the proportion of the data that is used for the test set. In the case we will make the test set 30% of our data, which is usually pretty standard.\n",
    "- The random_state parameter allows us to specify the random seed so that the results are reproducible.\n",
    "- The function returns a tuple of four objects:\n",
    "    - X_train: Dataframe with feature values for training set.\n",
    "    - X_test: Dataframe with feature values for testing set.\n",
    "    - y_train: Dataframe with labels (diagnosis) for training samples.\n",
    "    - y_test: Dataframe with labels (diagnosis) for testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Machine Learning Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have split our data into training and test sets, we are ready to train a machine learning model using scikit-learn! We will be using a Logistic Regression model that unlike the name, is actually used for classification tasks such as this one. The Logistic Regression algorithm relies on a function called the sigmoid function, which has the graph of an S-shaped curve and maps any real value to a value in the range (0, 1).\n",
    "\n",
    "The equation for the function is f(z) = 1/(1 + e^-z) and I have plotted this function below for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph of the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x111b8e6d8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD3CAYAAAAALt/WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wMfkhaaq1PcJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a58748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_values = np.linspace(-10, 10)\n",
    "y_values = 1/(1 + np.exp(-1*X_values))\n",
    "plt.plot(X_values, y_values, color='Blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model computes the weighted sum of each of the features and optimizes these weights in a manner similar to a neural network. Then, the weighted sum is passed to the sigmoid function, which returns a number from 0 to 1. If the number is greater than or equal to 0.5 we classify it as a positive class and if the number is less than 0.5 we classify it as a negative class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a Logistic Regression model is simple, as demonstrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression(C=2)\n",
    "log_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Our Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.93      0.97      0.95       105\n",
      "          M       0.95      0.88      0.91        66\n",
      "\n",
      "avg / total       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = log_model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation of Metrics in Classification Report\n",
    "\n",
    "The classification report that we printed out contains the following metrics:\n",
    "\n",
    "- precision - the ratio of correctly predicted positive observations (true positives) to the total predicted positive observations. In the context of this problem, for the M class, this is the number of correctly predicted diagnoses of malignant tumors divided by the total number of predicted malignant tumors. \n",
    "- recall - the ratio of correctly predicted positive observations to all observations actually in that class.\n",
    "- f1-score - a weighted average of precision and recall.\n",
    "\n",
    "Based on the classification report our model is very accurate considering we did not have to do much preprocessing.\n",
    "\n",
    "A more intuitive evaluation metric is accuracy, which is simply the number of correct predictions divided by the total number of predictions. Next we will take a look at this metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our logistic regression model has an accuracy of: 93.56725146198829 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Our logistic regression model has an accuracy of: {} %'.format(100*accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can do any better by experimenting with the value of C. This process is called hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1122119e8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAETCAYAAADZHBoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112204320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "C_vals = np.linspace(0.5, 10, num=50)\n",
    "accuracies = []\n",
    "\n",
    "for C_val in C_vals:\n",
    "    model = LogisticRegression(C=C_val)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    accuracies.append(100*accuracy_score(y_test, pred))\n",
    "    \n",
    "plt.plot(C_vals, np.array(accuracies), color='Red')\n",
    "plt.xlabel(\"Value of C parameter\")\n",
    "plt.ylabel(\"Accuracy of Model %\")\n",
    "plt.title(\"Value of C vs. Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can see that increasing the value of C up to 8 increases the cross-validation accuracy of our model, but going any further does not yield any improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This level of accuracy is pretty good, considering we did not have to do anything to complicated. This is the power of scikit-learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decision tree is exactly what the name implies. It is a model with nodes in a tree that represent the possible values of different features. Based on these values, we can take different steps in the tree until we reach a leaf node, which corresponds to a class prediction. (Image from: http://jmvidal.cse.sc.edu/talks/decisiontrees/allslides.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dt.png\" style=\"width: 600px; height: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.92      0.92      0.92       105\n",
      "          M       0.88      0.86      0.87        66\n",
      "\n",
      "avg / total       0.90      0.90      0.90       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = dtree.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our decision tree model has an accuracy of: 90.05847953216374 %\n"
     ]
    }
   ],
   "source": [
    "print('Our decision tree model has an accuracy of: {} %'.format(100*accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decision tree model did a little worse than our logistic regression model but this is expected since single decision trees are usually not strong models by themselves. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Methods - Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a single decision tree is not very strong, combining the predictions of many different decision trees using majority voting results in a very powerful model called a random forest. Next we will experiment with training a random forest model on the data! A random forest is essentially a classifier that combines the predictions of multiple decision trees using majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train a random forest classifier with 1000 decision trees and set n_jobs equal to -1 to allow for the decision trees to be constructed in parallel with multiple threads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(max_depth=6, n_jobs=-1, n_estimators=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          B       0.96      0.97      0.97       105\n",
      "          M       0.95      0.94      0.95        66\n",
      "\n",
      "avg / total       0.96      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our random forest model has an accuracy of: 95.90643274853801 %\n"
     ]
    }
   ],
   "source": [
    "print('Our random forest model has an accuracy of: {} %'.format(100*accuracy_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, our random forest model outperforms both the logistic regression and single decision tree models. Let's see how increasing the number of trees affects the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x112c68a58>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAJaCAYAAACfqGvSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1123e0a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_estimators_list = [1, 2, 5, 10, 50, 75, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200]\n",
    "accuracies = []\n",
    "\n",
    "for num_estimators in num_estimators_list:\n",
    "    model = RandomForestClassifier(max_depth=6, n_jobs=-1, n_estimators=num_estimators) \n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    accuracies.append(100*accuracy_score(y_test, pred))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(np.array(num_estimators_list), np.array(accuracies), color='Red')\n",
    "plt.xlabel(\"Number of decision trees\")\n",
    "plt.ylim(80, 100)\n",
    "plt.ylabel(\"Accuracy of Model %\")\n",
    "plt.title(\"Number of decision trees vs. Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above we can see that increasing the number of decision trees in our random forest improves the accuracy of our model up to a certain point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to get better results and where to go from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With each of these models, we did not have to do much preprocessing and still achieved excellent cross validation results! However, if we want to go a step further, we can try the following techniques:\n",
    "\n",
    "- More ensemble methods - Bagging, Adaboosting, etc.\n",
    "- Feature engineering - do some research and try to extract more features from the data.\n",
    "- Techniques for dimensionality reduction such as PCA, ICA, LDA.\n",
    "- Get more data!\n",
    "- Combine multiple models using majority voting or stacking!\n",
    "\n",
    "Feel free to explore further and check out the scikit-learn website to try out different models and experiment with different datasets."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
